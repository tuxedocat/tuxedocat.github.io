<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"  lang="ja">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1"/>

<title>『語学学習支援のための言語処理』を読みました． | miauhaus.log</title>



<link href="https://log.tuxedokatze.com/index.xml" rel="alternate" type="application/rss+xml" title="miauhaus.log" />

<link rel="stylesheet" href="/css/style.css"/><link rel='stylesheet' href='https://log.tuxedokatze.com/css/custom.css'><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<link rel="canonical" href="https://log.tuxedokatze.com/bookreview-nlp-for-language-learning/">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
</head>
<body>
<section class="section">
  <div class="container">
    <nav id="nav-main" class="nav">
      <div id="nav-name" class="nav-left">
        <a id="nav-anchor" class="nav-item" href="https://log.tuxedokatze.com">
          <h1 id="nav-heading" class="title is-4">miauhaus.log</h1>
        </a>
      </div>
      <div class="nav-right">
        <nav id="nav-items" class="nav-item level is-mobile"><a class="level-item" aria-label="github" href='https://github.com/tuxedocat'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22" />
  
</svg>
</i>
            </span>
          </a><a class="level-item" aria-label="linkedin" href='https://linkedin.com/in/yu-sawai-3071193b'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path stroke-width="1.8" d="m5.839218,4.101561c0,1.211972 -0.974141,2.194011 -2.176459,2.194011s-2.176459,-0.982039 -2.176459,-2.194011c0,-1.211094 0.974141,-2.194011 2.176459,-2.194011s2.176459,0.982917 2.176459,2.194011zm0.017552,3.94922l-4.388022,0l0,14.04167l4.388022,0l0,-14.04167zm7.005038,0l-4.359939,0l0,14.04167l4.360816,0l0,-7.370999c0,-4.098413 5.291077,-4.433657 5.291077,0l0,7.370999l4.377491,0l0,-8.89101c0,-6.915523 -7.829986,-6.66365 -9.669445,-3.259423l0,-1.891237z" />
  
</svg>
</i>
            </span>
          </a><a class="level-item" aria-label="flickr" href='https://www.flickr.com/photos/tuxedocat'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <circle cx="12" cy="12" r="10"></circle>
  <line x1="14.31" y1="8" x2="20.05" y2="17.94"></line>
  <line x1="9.69" y1="8" x2="21.17" y2="8"></line>
  <line x1="7.38" y1="12" x2="13.12" y2="2.06"></line>
  <line x1="9.69" y1="16" x2="3.95" y2="6.06"></line>
  <line x1="14.31" y1="16" x2="2.83" y2="16"></line>
  <line x1="16.62" y1="12" x2="10.88" y2="21.94"></line>
  
</svg>
</i>
            </span>
          </a><a class="level-item" aria-label="instagram" href='https://instagram.com/__tuxedocat__'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <rect x="2" y="2" width="20" height="20" rx="5" ry="5" />
  <path d="M16 11.37A4 4 0 1 1 12.63 8 4 4 0 0 1 16 11.37z" />
  <line x1="17.5" y1="6.5" x2="17.5" y2="6.5" />
  
</svg>
</i>
            </span>
          </a><a class="level-item" aria-label="rss" href='/index.xml'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M4 11a9 9 0 0 1 9 9"></path>
  <path d="M4 4a16 16 0 0 1 16 16"></path>
  <circle cx="5" cy="19" r="1"></circle>
  
</svg>
</i>
            </span>
          </a></nav>
      </div>
    </nav>

    <nav class="nav">
      

      
    </nav>

  </div>
  <script src="/js/navicon-shift.js"></script>
</section>
<section class="section">
  <div class="container">
    <div class="subtitle tags is-6 is-pulled-right">
      
      
<a class="subtitle is-6" href="/tags/book">#book</a>



  
  | <a class="subtitle is-6" href="/tags/nlp">#nlp</a>
  
  | <a class="subtitle is-6" href="/tags/review">#review</a>
  

      
    </div>
    <h2 class="subtitle is-6">November 22, 2017</h2>
    <h1 class="title">『語学学習支援のための言語処理』を読みました．</h1>
    
    <div class="content">
      <!-- textlint-enable -->

<p>『語学学習支援のための言語処理』を読者モニタとして献本していただきました 🎉<sup class="footnote-ref" id="fnref:thanks"><a href="#fn:thanks">1</a></sup></p>

<p></p>

<blockquote>
<p>奥村 学（監修），永田 亮： 語学学習支援のための言語処理（自然言語処理シリーズ 11），コロナ社（2017），URL: <a href="http://www.coronasha.co.jp/np/isbn/9784339027617">http://www.coronasha.co.jp/np/isbn/9784339027617</a> </br> ※以下の内容は，初版第1刷を対象としています．</p>
</blockquote>

<h2 id="短評">短評</h2>

<p>自然言語処理を用いた語学学習支援に関しては，今のところ唯一の書籍だと思います．
また，既存の類書（英書）やサーベイ論文と比べても，取り扱う範囲が幅広く，最近の手法がまとまっている点でよかったです．</p>

<p>まず，本書は，自然言語処理の側から語学学習支援に関わる方にとっては，心強いサーベイ資料となるはずです．
各種の語学学習支援タスクの取り扱いや，基礎解析技術（品詞タグ付けや依存構造解析など）を学習者コーパスに適用した場合の性能や，
評価尺度についての解説は，特に有益だと思います．</p>

<p>特徴的なのは，論文にはあまり書かれないような話題が，丁寧に説明されている点です．
この分野特有の難しさを強調するだけではなく，どうやってその難しさに向き合うかについての知見が書かれています．</p>

<p>たとえば，学習者コーパス構築のためのガイドラインや，どのような前処理や解析を適用すればよいか，
といった内容が詳しく説明されています．
KJコーパス構築の事例をはじめ，永田先生自身の経験や知見が反映されている点で，本書のハイライトかもしれません．
実用的な知識であるというだけでなく，研究の指針としても教わることが多いと感じました．</p>

<p>一方，本書ではあまり触れられていない事項もあります．
本書では，基礎となる構文解析や機械学習アルゴリズムの解説は少なめです．
今すぐ手法を実装したい，という場合には他の文献にあたる必要がありそうです．</p>

<p>他の分野から語学教育に関わる方と，自然言語処理の側との橋渡しになる点でも，意義があると感じます．
これを契機に，教育効果の測定や，より良いフィードバック提供の方法などの面で，さらに交流が進むことを期待します．</p>

<hr />

<h2 id="内容紹介">内容紹介</h2>

<p>内容の整理も兼ねて，全体の内容を紹介します．</p>

<h3 id="1-3-基礎編">1 ~ 3: 基礎編</h3>

<p><strong>「イントロダクション」</strong>では，語学学習<sup class="footnote-ref" id="fnref:langlearn"><a href="#fn:langlearn">2</a></sup>支援の目的が示されています．
語学学習の学習効果を最大化する，という目的のためには，学習者自身への支援と，教師への支援の大きく2つがあります．
本書では，主に日本語と英語を対象としています．
特に，「日本語を母語とする人が英語を学習する場合」を想定した事例や手法の説明に重点が置かれています．</p>

<p><strong>「処理の対象となるデータ」</strong>では，学習者コーパス<sup class="footnote-ref" id="fnref:corpus"><a href="#fn:corpus">3</a></sup>の特徴やその重要性が強調されています．</p>

<p>学習者の言語機能や学習の過程を言語現象として捉えられる点で，学習者コーパスは重要な情報源となります．
自然言語処理においては，辞書の構築や，機械学習モデルの訓練データ，そして性能評価にも使われます．</p>

<p>歴史的経緯として，最初期の学習者コーパス ICLE (International Corpus of Learner English) から，最近の言語資源整備の取り組みまで，丁寧に紹介されています．
公開済みコーパスの一覧にとどまらず，自力でのコーパス構築についても解説されています．
計画から始まり，言語データの収集・各種のアノテーション（誤り情報など）・評価，そして公開までの一連の流れが示されます．</p>

<p>章の後半では，学習者コーパスの特徴を概観します．
綴りや文法の誤りだけではなく，句読点抜け落ちなど，その傾向は学習者の属性によって様々であることが言及されます．
学習者コーパスを注意深く観察しないと，なかなか気付けない問題もあるようです<sup class="footnote-ref" id="fnref:absence-of-period-ref"><a href="#fn:absence-of-period-ref">4</a></sup>．</p>

<p><strong>「語学学習支援のための言語処理を支える要素技術」</strong>では，自然言語処理における基礎解析が概説されています．
特に，文分割から構文解析までがここでの対象となっています．
手法自体に深入りはしませんが，学習者の文章に対して基礎解析技術がどの程度機能するか，という情報がまとめられているのが特徴です．
こうした解析自体を詳しく知りたい場合は，同シリーズの『構文解析』などがおすすめです．</p>

<p>問題設定と対象とする言語データ，そして自然言語処理の要素技術に対する知識がそろったところで，いよいよ語学学習支援のタスクが紹介されます．</p>

<h3 id="4-5-学習者支援">4 ~ 5: 学習者支援</h3>

<p>ここからはそれぞれのタスクが，以下のような構成で説明されます．</p>

<ol>
<li>タスク概要</li>
<li>性能と実例</li>
<li>理論と技術</li>
<li>実際的な情報</li>
<li>発展的内容と残された問題</li>
</ol>

<p>語学学習を行う学習者本人への支援としては，「ライティング支援」と「リーディング支援」が紹介されています．</p>

<h4 id="4-ライティング支援">4. ライティング支援</h4>

<p>本記事では（自由作文に対する）文法誤り検出・訂正を取り上げます．
よく研究されているテーマであり，ACL<sup class="footnote-ref" id="fnref:acl"><a href="#fn:acl">5</a></sup> などの自然言語処理の国際会議で，ワークショップや関連するセッションが設けられています．
そして，一番身近な語学学習支援の実例かもしれません．
たとえば，<a href="https://www.grammarly.com/">Grammarly</a> のように，英語の文法誤り検出・訂正サービスは，すでに実用段階にあるといえそうです．</p>

<p>ひとことでライティング支援といっても，学習者にとって難しい文法事項は異なります．
たとえば英語の場合，「主語と動詞の一致」，「前置詞の選択」，「冠詞の選択・有無」など様々なものが挙げられます．</p>

<p>このように対象となる誤りの種類は多様である一方，自然言語処理の問題としての取り扱いとしては共通する部分も多いです．
ここでは代表的な手法として，（人手による）規則を用いた手法，言語モデルを用いた手法，SVMや最大エントロピー法などの機械学習を用いた手法が概説されています．</p>

<p>手法の種類も，そこで用いられるモデルも多様ですが，本書では次のことが強調されています<sup class="footnote-ref" id="fnref:gec-ref"><a href="#fn:gec-ref">6</a></sup>:</p>

<blockquote>
<p>語学学習支援を目的とした文法誤り検出/訂正では，検出/訂正性能だけではなく，つねに，より高い学習効果のことを意識するべきであろう．</p>
</blockquote>

<p>これを反映して，この章では評価の際の注意事項や，学習者への適切なフィードバックの重要性についても大きく紙面が割かれています．</p>

<h4 id="5-リーディング支援">5. リーディング支援</h4>

<p>文章中の難解な語の検出や，より平易な表現への言い換えが含まれます．</p>

<p>イメージを示すために，言い換えタスクの例を以下に引用します<sup class="footnote-ref" id="fnref:paraphrasing-ref"><a href="#fn:paraphrasing-ref">7</a></sup>:</p>

<blockquote>
<p>入力文: The Association for Natural Language Processing was <strong>established</strong> in 1994. </br>
出力文: The Association for Natural Language Processing was <strong>started</strong> in 1994.</p>
</blockquote>

<p>英英辞書を使って，英文を英語のまま，難しい単語の指す概念を理解しようとしたり，
自分が知っているより簡単な単語と結びつけて学習する，という場面のような学習効果を狙っています．</p>

<p>「難解語の同定」では，文中の語が難解であるかどうかを判定します．
あらかじめ定めておいた難解語の辞書を使うこともできますが，文脈によって難解かどうかが変わる場合には対応できません．
辞書に加え，言語モデルの確率値や品詞列などの周辺文脈の特徴を利用した分類モデルを用いることが，ひとつの改善策となります．</p>

<p>「難解語の言い換え」のためには，さらに言い換え規則の獲得と，その適用が必要になります．
規則の獲得のためには，類義語辞書を使うこともできますが，より広範囲な規則を得るための手法も提案されています．
対応関係のある2つのコーパス（パラレルコーパス）<sup class="footnote-ref" id="fnref:simple-wikipedia"><a href="#fn:simple-wikipedia">8</a></sup>を用いる手法です．
たとえば，すべての単語の分散表現を計算してから，何らかの類似度尺度を求めれば，類似した分散表現を持つような単語同士の対応が得られます．
また，パラレルコーパスではなく，単一のコーパスからこうした規則を獲得する手法も提案されているようです．</p>

<p>評価方法としては，人手で作成した言い換え結果との自動評価だけでなく，「平易性」，「文法性」，「意味の保持」という3つの観点からの主観評価も用いられるようです．</p>

<p>タスク自体の主な課題は，どこまでを難解語とするか，どこまで言い換えればよいか，というものです．
そもそも，同じような属性の学習者であっても，個人ごとに習熟度は異なります．
これに対応するため，学習者の語彙知識を問う質問などにより語彙力を推定し，個人差に対応する手法が提案されているようです．</p>

<h3 id="6-7-教師支援">6 ~ 7: 教師支援</h3>

<p>最後の2つの章では，「教材作成支援」と「学習者の能力／特徴の分析」という，教育者の側への支援について書かれています．
これらに共通する目的は，教育者の負担軽減です．
後者は，学習者コーパスの分析や，言語現象への仮説を立てるための補助的な情報にもなり得ます．</p>

<h4 id="6-教材作成支援">6. 教材作成支援</h4>

<p>「教材作成支援」の中でも「語彙問題生成」は，学習者が受験する語学試験にも関連する点で，特色のあるタスクです．
このタスクでは，類義語選択問題や穴埋め形式の問題を生成します．
イメージとしては，TOEFL® Test のリーディングセクションに含まれる類義語選択問題<sup class="footnote-ref" id="fnref:toefl-example"><a href="#fn:toefl-example">9</a></sup>です．</p>

<h4 id="7-学習者の能力-特徴の分析">7. 学習者の能力/特徴の分析</h4>

<p>先の教材作成支援では，試験問題の作成に利用できるタスクが紹介されました．
この章のはじめの「言語能力の自動評価」では，主に作文（エッセイ）の自動採点が紹介されます．</p>

<p>言語能力の測定はそもそも難しいものなので，ここでは，人間による採点を再現することをひとまずの目標としています．
取り扱いとしては，何段階かの評価や点数への回帰問題とすることが多いようです．</p>

<p>続く「学習者コーパスからの特徴表現抽出」と「母語干渉の分析」から得られる結果は，それ自体が知識源となるだけではなく，
他のタスクにおける特徴（素性）としても重要です．
たとえば，学習者の母語によって前置詞誤りの傾向が異なるという知識を利用して，それを事前分布として利用する手法が提案されています．</p>

<hr />

<h2 id="感想">感想</h2>

<p>ここからはきわめて個人的な感想となるので，常体に戻す．</p>

<p>僕は英語学習者支援の研究をしていたことがある，というだけの者なのだが，
たまたま縁があって，
自分自身が関わっていた分野の知識が集約された本をじっくりと読む機会に恵まれた．</p>

<p>全体を通して，語学学習支援の目的を見失わないように，という課題意識が表明されていたように思う．
個人的には，それがハイライトだと解釈した．
学習者支援の思想的なところの重要性や，自然言語処理だけでは済まないタスクだということを再認識した<sup class="footnote-ref" id="fnref:regret"><a href="#fn:regret">10</a></sup>．</p>

<p>記事を書いている間，<a href="https://ctrl-x-s.blog/2017/11/06/%e3%83%99%e3%83%b3%e3%83%81%e3%83%9e%e3%83%bc%e3%82%af%e3%81%ae%e5%8a%9f%e7%bd%aa/">『ベンチマークの功罪』（Google 賀沢さんのブログ）</a> で指摘されていたようなことを考えていた．
語学学習支援での状況はどうなのだろうか，と思ったが，本書や他の論文でも課題意識を表明している方は多い様子なので，大丈夫なのかもしれない．</p>

<p>そもそも，タスクの提案と，それに適した学習者コーパスの構築・公開，評価指標を整備すること自体，この分野ではかなり苦労するものだと思っている．
しかし，本書でも触れられていた Learner Corpus Association の発足など，状況は着実に良くなっている気がした．
最近のACLでの関連論文をちらっと眺めてみると，評価手法そのものに関する論文<sup class="footnote-ref" id="fnref:eval-gec"><a href="#fn:eval-gec">11</a></sup> があったので，ポジティブな印象は強まった．
今後は，実運用（教育現場）での効果測定のような問題と向き合うことになるんだろうか．</p>

<p><a href="http://b.hatena.ne.jp/entry/" class="hatena-bookmark-button" data-hatena-bookmark-layout="basic" title="このエントリーをはてなブックマークに追加"><img src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" alt="このエントリーをはてなブックマークに追加" width="20" height="20" style="border: none;" /></a><script type="text/javascript" src="https://b.st-hatena.com/js/bookmark_button.js" charset="utf-8" async="async"></script></p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:thanks">コロナ社様より．この度はありがとうございました．
 <a class="footnote-return" href="#fnref:thanks"><sup>[return]</sup></a></li>
<li id="fn:langlearn">本書では，第二言語習得と語学学習とを，「対象言語が日常的に使用されている環境下であるか」という基準で区別しています．この区別において，語学学習という用語は「対象言語が日常的に使用されていない環境下での学習」を指します．たとえば「英語が母語ではない人が日本の学校で英語を学習する」という状況です．
 <a class="footnote-return" href="#fnref:langlearn"><sup>[return]</sup></a></li>
<li id="fn:corpus">コーパスとは，言語データを集約し，計算機で扱えるようにしたものを指します．
 <a class="footnote-return" href="#fnref:corpus"><sup>[return]</sup></a></li>
<li id="fn:absence-of-period-ref">p.12 では，中学生の書いた英文の観察から「文末のピリオド脱落」という問題を初めて認識した，という永田先生の経験談が書かれています．
 <a class="footnote-return" href="#fnref:absence-of-period-ref"><sup>[return]</sup></a></li>
<li id="fn:acl">自然言語処理のトップカンファレンスのひとつ．<a href="http://cl.sd.tmu.ac.jp/groups/seminars/conferences">首都大学東京の小町先生による関連学会の紹介</a>が参考になります．
 <a class="footnote-return" href="#fnref:acl"><sup>[return]</sup></a></li>
<li id="fn:gec-ref">p.88 より．
 <a class="footnote-return" href="#fnref:gec-ref"><sup>[return]</sup></a></li>
<li id="fn:paraphrasing-ref">p.108 より．
 <a class="footnote-return" href="#fnref:paraphrasing-ref"><sup>[return]</sup></a></li>
<li id="fn:simple-wikipedia"><a href="https://simple.wikipedia.org/wiki/Main_Page">Simple English Wikipedia</a> がよく利用される印象があります．ただし，言い換えタスクのための言語資源として最適かどうかには議論があるようです．（Xu, W., Callison-Burch, C., &amp; Napoles, C. (2015). Problems in Current Text Simplification Research: New Data Can Help. TACL. など．）
 <a class="footnote-return" href="#fnref:simple-wikipedia"><sup>[return]</sup></a></li>
<li id="fn:toefl-example"><a href="https://www.ets.org/Media/Tests/TOEFL/pdf/SampleQuestions.pdf">ETSが公開しているサンプル</a>の <em>The word &ldquo;&hellip;&rdquo; on line N is closest in meaning to:</em> という問題．
 <a class="footnote-return" href="#fnref:toefl-example"><sup>[return]</sup></a></li>
<li id="fn:regret">自分自身が英語学習者支援のテーマで研究していたときにも，意識していたはずだが……．
 <a class="footnote-return" href="#fnref:regret"><sup>[return]</sup></a></li>
<li id="fn:eval-gec">文法誤り訂正における評価手法の再考．Sakaguchi, K., Napoles, C., Post, M., &amp; Tetreault, J. (2016). Reassessing the Goals of Grammatical Error Correction: Fluency Instead of Grammaticality. Transactions of the Association of Computational Linguistics, 4, 169–182.
 <a class="footnote-return" href="#fnref:eval-gec"><sup>[return]</sup></a></li>
</ol>
</div>
      
    </div>
    
  </div>
</section>



<section class="section">
  <div class="container has-text-centered">
    <p><a href="https://github.com/tuxedocat/tuxedocat.github.io">©2011-2019 tuxedocat</a></p>
    
  </div>
</section>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-46681113-3', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>




</body>
</html>

